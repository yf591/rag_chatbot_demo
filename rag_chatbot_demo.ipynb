{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yf591/rag_chatbot_demo/blob/main/rag_chatbot_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSpnWBP5ELSI"
      },
      "source": [
        "# rag-chatbot-demoのデモ\n",
        "このノートブックでは以下の内容を理解＆学習しながら実行することができます。\n",
        "\n",
        "- 必要なライブラリのインストールと環境設定\n",
        "- Hugging Faceからモデルを用いたStreamlitのデモアプリ\n",
        "\n",
        "準備として、HuggingFaceとngrokのアカウントを作成し、\n",
        "それぞれのAPIトークンを取得する必要があります。\n",
        "\n",
        "### 注意事項\n",
        "「rag-chatbot-demo」では、GPUを使用します。\n",
        "\n",
        "これらを実行する際は、Google Colab画面上のメニューから「編集」→ 「ノートブックの設定」\n",
        "\n",
        "「ハードウェアアクセラレーター」の項目の中から、「T4 or L4 or A100」を選択してください。（推奨はL4以上）\n",
        "\n",
        "### ⚠️ Google Colab特有の注意点\n",
        "\n",
        "**FAISS問題の対処**\n",
        "- Google Colabでは`faiss-gpu`が利用できないため、`faiss-cpu`を使用します。そのため若干精度が落ちます。\n",
        "- このノートブックでは自動的に適切なバージョンをインストールします\n",
        "\n",
        "**よくあるエラーと対処法**\n",
        "- 「関連する情報が見つかりませんでした」→ ベクトルストアの問題（後述のトラブルシューティングセルを実行）\n",
        "- GPU認識しない → ランタイム再起動\n",
        "- メモリ不足 → 高RAMオプション有効化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhtHkJOgELSL"
      },
      "source": [
        "# 環境変数の設定\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-FjBp4MMQHM"
      },
      "source": [
        "GitHubから演習用のコードをCloneします。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIXMavdDEP8U"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/yf591/rag_chatbot_demo.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XC8n7yZ_vs1K"
      },
      "source": [
        "必要なAPIトークンを.envに設定します。\n",
        "\n",
        "「rag-chatbot-demo」の配下に、「.env_template」ファイルが存在しています。\n",
        "\n",
        "隠しファイルのため表示されていない場合は、画面左側のある、目のアイコンの「隠しファイルの表示」ボタンを押してください。\n",
        "\n",
        "「.env_template」のファイル名を「.env」に変更します。「.env」ファイルを開くと、以下のような中身になっています。\n",
        "\n",
        "\n",
        "```\n",
        "HUGGINGFACE_TOKEN=\"********\"\n",
        "NGROK_TOKEN=\"********\"\n",
        "```\n",
        "ダブルクオーテーションで囲まれた文字列をHuggingfaceのアクセストークンと、ngrokの認証トークンで書き変えてください。\n",
        "\n",
        "それぞれのアカウントが作成済みであれば、以下のURLからそれぞれのトークンを取得できます。\n",
        "\n",
        "- Huggingfaceのアクセストークン\n",
        "https://huggingface.co/docs/hub/security-tokens\n",
        "\n",
        "- ngrokの認証トークン\n",
        "https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "\n",
        "書き換えたら、「.env」ファイルをローカルのPCにダウンロードしてください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Py1BFS5RqcSS"
      },
      "source": [
        "「.env」ファイルを読み込み、環境変数として設定します。次のセルを実行し、最終的に「True」が表示されていればうまく読み込めています。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bvEowFfg5lrq"
      },
      "outputs": [],
      "source": [
        "!pip install python-dotenv\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "%cd /content/rag_chatbot_demo\n",
        "load_dotenv(find_dotenv())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-T8tFpyELSO"
      },
      "source": [
        "# rag-chatbot-demoの起動"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqogFQKnELSO"
      },
      "source": [
        "\n",
        "ディレクトリ「rag-chatbot-demo」に移動します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UeEjlJ7uELSO"
      },
      "outputs": [],
      "source": [
        "%cd /content/rag_chatbot_demo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XUH2AstELSO"
      },
      "source": [
        "必要なライブラリをインストールします。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-p1cCOjlvto"
      },
      "source": [
        "## ⚠️ 重要：ベクトルストアの確認\n",
        "\n",
        "ここでは**ベクトルストアを作成**して、FAISSが正しく動作するかを確認します。\n",
        "\n",
        "まず、次のセルを実行して\n",
        "- FAISSライブラリの動作確認\n",
        "- ベクトルストアファイルの存在確認\n",
        "- GPU環境の確認\n",
        "\n",
        "を行います。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDqvI4V3ELSO"
      },
      "outputs": [],
      "source": [
        "# Google Colab用の依存関係インストール\n",
        "\n",
        "# 1. まずFAISSを個別にインストール（Google Colab対応）\n",
        "print(\"=== FAISSライブラリのインストール ===\")\n",
        "!pip install faiss-cpu  # Google ColabではCPU版を使用\n",
        "\n",
        "# 2. その他の依存関係をインストール\n",
        "print(\"\\n=== その他の依存関係インストール ===\")\n",
        "!pip install streamlit\n",
        "!pip install transformers>=4.36.0\n",
        "!pip install torch>=2.0.0\n",
        "!pip install langchain>=0.3.0\n",
        "!pip install langchain-community>=0.3.0\n",
        "!pip install langchain-huggingface>=0.1.0\n",
        "!pip install sentence-transformers>=2.2.0\n",
        "!pip install PyMuPDF\n",
        "!pip install accelerate>=0.20.0\n",
        "!pip install bitsandbytes>=0.41.0\n",
        "!pip install huggingface_hub>=0.16.0\n",
        "!pip install python-dotenv\n",
        "!pip install pyngrok\n",
        "!pip install toml\n",
        "\n",
        "print(\"\\n✅ 依存関係のインストール完了\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPL9RQRZlvto"
      },
      "outputs": [],
      "source": [
        "# Google Colab用ベクトルストア確認・作成\n",
        "print(\"=== ベクトルストア状態確認 ===\\n\")\n",
        "\n",
        "# まず軽量版でベクトルストア作成（Google Colab推奨）\n",
        "print(\"🔄 Google Colab用軽量ベクトルストア作成中...\")\n",
        "!python pdf_processor_light.py\n",
        "\n",
        "print(\"\\n=== インストール確認 ===\")\n",
        "\n",
        "try:\n",
        "    import faiss\n",
        "    print(f\"✅ FAISS: バージョン {faiss.__version__}\")\n",
        "except ImportError as e:\n",
        "    print(f\"❌ FAISS インポートエラー: {e}\")\n",
        "\n",
        "try:\n",
        "    from langchain_community.vectorstores import FAISS as LangChainFAISS\n",
        "    from langchain_huggingface import HuggingFaceEmbeddings\n",
        "    print(\"✅ LangChain FAISS統合: OK\")\n",
        "except ImportError as e:\n",
        "    print(f\"❌ LangChain インポートエラー: {e}\")\n",
        "\n",
        "# ベクトルストアの存在確認\n",
        "import os\n",
        "if os.path.exists('./vector_store/index.faiss'):\n",
        "    print(\"✅ ベクトルストアファイル: 存在\")\n",
        "\n",
        "    # ファイルサイズ確認\n",
        "    faiss_size = os.path.getsize('./vector_store/index.faiss')\n",
        "    pkl_size = os.path.getsize('./vector_store/documents.pkl') if os.path.exists('./vector_store/documents.pkl') else 0\n",
        "    print(f\"📊 index.faiss: {faiss_size/1024:.1f}KB\")\n",
        "    print(f\"📊 documents.pkl: {pkl_size/1024:.1f}KB\")\n",
        "else:\n",
        "    print(\"❌ ベクトルストアファイル: 見つかりません\")\n",
        "    print(\"💡 PDF前処理が必要な可能性があります\")\n",
        "\n",
        "print(\"\\n=== GPU確認 ===\")\n",
        "import torch\n",
        "print(f\"CUDA利用可能: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU名: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPUメモリ: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB\")\n",
        "\n",
        "print(\"\\n=== ベクトルストア動作テスト ===\")\n",
        "try:\n",
        "    from langchain_huggingface import HuggingFaceEmbeddings\n",
        "    from langchain_community.vectorstores import FAISS\n",
        "\n",
        "    # 埋め込みモデル初期化\n",
        "    embeddings = HuggingFaceEmbeddings(\n",
        "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "        model_kwargs={'device': 'cpu'}\n",
        "    )\n",
        "\n",
        "    # ベクトルストア読み込みテスト\n",
        "    vector_store = FAISS.load_local(\n",
        "        \"./vector_store\",\n",
        "        embeddings,\n",
        "        allow_dangerous_deserialization=True\n",
        "    )\n",
        "\n",
        "    # 簡単な検索テスト\n",
        "    test_results = vector_store.similarity_search(\"福山\", k=1)\n",
        "    if test_results:\n",
        "        print(f\"✅ ベクトルストア動作: 正常（{len(test_results)}件取得）\")\n",
        "        print(f\"📄 テスト結果: {test_results[0].page_content[:100]}...\")\n",
        "    else:\n",
        "        print(\"⚠️ ベクトルストア動作: 検索結果なし\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ ベクトルストアエラー: {e}\")\n",
        "    print(\"🔧 修復が必要です - 次のトラブルシューティングセルを実行してください\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZO31umGZELSO"
      },
      "source": [
        "ngrokとhuggigfaceのトークンを使用して、認証を行います。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPxTiEWQELSO"
      },
      "outputs": [],
      "source": [
        "!ngrok authtoken $$NGROK_TOKEN\n",
        "!huggingface-cli login --token $$HUGGINGFACE_TOKEN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rfq0WRUblvtp"
      },
      "source": [
        "## 🔧 トラブルシューティング（必要時のみ実行）\n",
        "\n",
        "**もし「関連する情報が見つかりませんでした」というエラーが出る場合**は、以下のセルを実行してベクトルストアを修復してください。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "640Onzhjlvtp"
      },
      "outputs": [],
      "source": [
        "# ベクトルストアの修復（エラー時のみ実行）\n",
        "print(\"=== ベクトルストア修復処理 ===\")\n",
        "\n",
        "try:\n",
        "    # ベクトルストアの状態確認\n",
        "    !python check_vector_store.py\n",
        "\n",
        "    print(\"\\n=== ベクトルストア修復実行 ===\")\n",
        "    !python fix_vector_store.py\n",
        "\n",
        "    print(\"\\n=== 修復後の確認 ===\")\n",
        "    !python check_vector_store.py\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"エラー: {e}\")\n",
        "    print(\"\\n💡 手動でPDF前処理を実行します...\")\n",
        "    !python pdf_processor_light.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNrS_6oQlvtp"
      },
      "outputs": [],
      "source": [
        "# RAGシステムの動作テスト\n",
        "print(\"=== RAGシステム動作テスト ===\")\n",
        "\n",
        "try:\n",
        "    from rag_system_simple import RAGSystemSimple\n",
        "\n",
        "    # シンプル版でテスト\n",
        "    rag_simple = RAGSystemSimple()\n",
        "\n",
        "    # テスト質問\n",
        "    test_question = \"福山市について教えてください\"\n",
        "    print(f\"テスト質問: {test_question}\")\n",
        "\n",
        "    # 文書検索テスト\n",
        "    docs = rag_simple.retrieve_documents(test_question, k=2)\n",
        "\n",
        "    if docs:\n",
        "        print(f\"\\n✅ 検索成功: {len(docs)}件の関連文書を発見\")\n",
        "        for i, doc in enumerate(docs[:1]):  # 最初の1件を表示\n",
        "            print(f\"\\n--- 文書 {i+1} ---\")\n",
        "            print(f\"ソース: {doc.get('metadata', {}).get('source', '不明')}\")\n",
        "            print(f\"内容: {doc.get('content', '')[:200]}...\")\n",
        "        print(\"\\n🎉 RAGシステムは正常に動作しています！\")\n",
        "    else:\n",
        "        print(\"\\n❌ 文書検索に失敗しました\")\n",
        "        print(\"ベクトルストアに問題がある可能性があります\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ テストエラー: {e}\")\n",
        "    print(\"上記の修復処理を実行してください\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K52h1zTJlvtq"
      },
      "source": [
        "### ✅ 成功の確認方法\n",
        "\n",
        "上記のテストで以下が表示されれば準備完了です。\n",
        "\n",
        "1. **FAISS**: ✅ バージョン表示\n",
        "2. **LangChain FAISS統合**: ✅ OK\n",
        "3. **ベクトルストアファイル**: ✅ 存在\n",
        "4. **検索成功**: ✅ X件の関連文書を発見\n",
        "5. **RAGシステムは正常に動作しています！**\n",
        "\n",
        "❌ エラーが出る場合は、上記のトラブルシューティングセルを実行してください。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Streamlitアプリの起動"
      ],
      "metadata": {
        "id": "Q_kBbNjH3ZAv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dz4WrELLELSP"
      },
      "source": [
        "stramlitでHuggingfaceのトークン情報を扱うために、streamlit用の設定ファイル（.streamlit）を作成し、トークンの情報を格納します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W184-a7qFP0W"
      },
      "outputs": [],
      "source": [
        "# .streamlit/secrets.toml ファイルを作成\n",
        "import os\n",
        "import toml\n",
        "\n",
        "# 設定ファイルのディレクトリ確保\n",
        "os.makedirs('.streamlit', exist_ok=True)\n",
        "\n",
        "# 環境変数から取得したトークンを設定ファイルに書き込む\n",
        "secrets = {\n",
        "    \"huggingface\": {\n",
        "        \"token\": os.environ.get(\"HUGGINGFACE_TOKEN\", \"\")\n",
        "    }\n",
        "}\n",
        "\n",
        "# 設定ファイルを書き込む\n",
        "with open('.streamlit/secrets.toml', 'w') as f:\n",
        "    toml.dump(secrets, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fK0vI_xKELSP"
      },
      "source": [
        "アプリを起動します。\n",
        "\n",
        "rag-chatbot-demoでは、Huggingfaceからモデルをダウンロードするため、初回起動には2分程度時間がかかります。\n",
        "\n",
        "この待ち時間を利用して、app.pyのコードを確認してみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBQyTTWTELSP"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "public_url = ngrok.connect(8501).public_url\n",
        "print(f\"公開URL: {public_url}\")\n",
        "!streamlit run app.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xvm8sWFPELSP"
      },
      "source": [
        "後片付けとして、使う必要のないngrokのトンネルを削除します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFJC2TmZELSP"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.kill()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}